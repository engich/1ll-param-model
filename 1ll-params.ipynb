{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, os, glob, random\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_(weights):\n",
    "    for weight in weights:\n",
    "        in_dim, out_dim = weight.shape[-2:]\n",
    "        np.copyto(dst=weight, src=np.random.randn(*weight.shape) * np.sqrt(2. / (in_dim + out_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(model, val, y_val):\n",
    "    output = model(val)\n",
    "    y_hat = np.argmax(output, axis=1)\n",
    "    return accuracy_score(y_val, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RELUFunction():\n",
    "    def forward(self, x):\n",
    "        self.a = relu(x)\n",
    "        return self.a\n",
    "\n",
    "    def backward(self, grad):\n",
    "        return 1. * (x > 0) * grad.reshape(self.a.shape)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "    def __init__(self, eps=1e-15):\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        self.target = target.squeeze()\n",
    "        self.output = output.squeeze()\n",
    "        return ((self.target - self.output)**2).mean()\n",
    "\n",
    "    def backward(self):\n",
    "        return self.output - self.target\n",
    "\n",
    "    def __call__(self, output, target):\n",
    "        return self.forward(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear(in_dim, out_dim):\n",
    "    W = np.random.normal(loc=0, scale=0.1, size=(in_dim, out_dim))\n",
    "    b = np.random.normal(loc=0, scale=0.1, size=(1, out_dim))\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer():\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.W, self.b = Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.data = x\n",
    "        z = np.dot(x, self.W) + self.b\n",
    "        return z\n",
    "\n",
    "    def backward(self, grad):\n",
    "        dW = np.dot(self.data.T, grad)\n",
    "        db = grad.sum(axis=0)\n",
    "        dx = np.dot(grad, self.W.T)\n",
    "        return dW, db, dx\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.W, self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = 1. - p\n",
    "\n",
    "    def forward(self, x, training):\n",
    "        if training:\n",
    "            self.mask = np.random.binomial(1, self.p, size=x.shape)\n",
    "            res = x * self.mask / self.p\n",
    "            return res.reshape(x.shape)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def backward(self, grad):\n",
    "        return grad * self.mask / self.p # you need to scale signal\n",
    "\n",
    "    def __call__(self, x, training):\n",
    "        return self.forward(x, training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, alpha=0.1, beta1=0.9, beta2=0.999, eps=1e-8, weight_decay=0.01):\n",
    "        self.alpha = alpha\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.t = 0\n",
    "\n",
    "    def step(self, grads, params):\n",
    "        if self.t == 0:\n",
    "            self.m = {k: np.zeros_like(v) for k, v in enumerate(params)}\n",
    "            self.v = {k: np.zeros_like(v) for k, v in enumerate(params)}\n",
    "        self.t += 1\n",
    "        for k, (param, grad) in enumerate(zip(params, grads)):\n",
    "            self.m[k] = self.beta1*self.m[k] + (1 - self.beta1)*grad\n",
    "            self.v[k] = self.beta2*self.v[k] + (1 - self.beta2)*(grad**2)\n",
    "            m_hat = self.m[k] / (1 - self.beta1**self.t)\n",
    "            v_hat = self.v[k] / (1 - self.beta2**self.t)\n",
    "            param -= self.alpha * (m_hat / (np.sqrt(v_hat) + self.eps) + self.weight_decay*param)\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNetwork:\n",
    "    def __init__(self):\n",
    "        self.fc1 = LinearLayer(36, 32)\n",
    "        self.dp1 = Dropout(0.1) ###\n",
    "        self.fc2 = LinearLayer(32, 16)\n",
    "        self.dp2 = Dropout(0.1) ###\n",
    "        self.fc3 = LinearLayer(16, 4)\n",
    "        self.dp3 = Dropout(0.1) ###\n",
    "        self.relu = RELUFunction()\n",
    "\n",
    "        xavier_(self.fc1.parameters())\n",
    "        xavier_(self.fc2.parameters())\n",
    "        xavier_(self.fc3.parameters())\n",
    "\n",
    "        self.training = True ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.data = x\n",
    "        z1 = self.fc1(x)\n",
    "        z1 = self.dp1.forward(z1, self.training) ###\n",
    "        self.a1 = self.relu(z1)\n",
    "        z2 = self.fc2(self.a1)\n",
    "        z2 = self.dp2.forward(z2, self.training) ###\n",
    "        self.a2 = relu(z2)\n",
    "        z3 = self.fc3(self.a2)\n",
    "        z3 = self.dp3.forward(z3, self.training) ###\n",
    "        self.a3 = relu(z3)\n",
    "        return self.a2\n",
    "\n",
    "    def gradients(self):\n",
    "        dz3 = self.loss_function.backward()\n",
    "        dz3 = self.dp3.backward(dz3) ###\n",
    "        dW3, db3, dx3 = self.fc3.backward(dz3)\n",
    "        dz2 = self.relu.backward(dz3)\n",
    "        dz2 = self.dp2.backward(dz2) ###\n",
    "        dW2, db2, dx2 = self.fc2.backward(dz2)\n",
    "        dz1 = self.relu.backward(dx2)\n",
    "        dz1 = self.dp1.backward(dz1) ###\n",
    "        dW1, db1, _ = self.fc1.backward(dz1)\n",
    "        return (dW1, db1, dW2, db2)\n",
    "\n",
    "    def backward(self, loss_function):\n",
    "        self.loss_function = loss_function\n",
    "        return self.gradients()\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.fc1.parameters() + self.fc2.parameters() + self.fc3.parameters()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def size(self):\n",
    "        s = 0\n",
    "        for param in self.parameters():\n",
    "            s += param.size\n",
    "        return s\n",
    "\n",
    "    def eval(self): ###\n",
    "        self.training = False ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeedforwardNetwork()\n",
    "loss_function = MSELoss()\n",
    "optimizer = Adam(alpha=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read onell runtime data\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df_onell = pd.DataFrame()\n",
    "\n",
    "path = './new_logs'\n",
    "\n",
    "for file_name in glob.iglob(path + '/**/**.csv', recursive=True):\n",
    "    #temp = pd.read_json(file_name)\n",
    "    temp = pd.read_csv(file_name)\n",
    "    df_onell = df_onell.append(temp, ignore_index = True)\n",
    "\n",
    "df_onell = df_onell.astype(float)\n",
    "df_onell = df_onell.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows with min average runtime\n",
    "\n",
    "mean_runtime = df_onell.groupby(['n', 'dummy', 'epi', 'neu', 'rug', 'lambdaOne', 'lambda2', 'crossover', 'mutation'])['runtime'].transform('mean')\n",
    "df_onell['runtime_mean'] = mean_runtime\n",
    "\n",
    "idx = df_onell.groupby(['n', 'dummy', 'epi', 'neu', 'rug'])['runtime_mean'].transform('max') == df_onell['runtime_mean']\n",
    "df_onell = df_onell[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read flacco data\n",
    "\n",
    "# To fix the probem with the way output data is structured after multiple runs of onell\n",
    "\n",
    "with open('flacco_logs.txt') as raw_file:\n",
    "    with open('flacco_logs_fixed.txt', 'wt') as json_file:\n",
    "        for line in raw_file:\n",
    "            json_file.write(line.replace('}[', '}\\n,'))\n",
    "\n",
    "# Read json data and convert to pandas dataframe\n",
    "\n",
    "df_flacco = None\n",
    "\n",
    "with open('flacco_logs_fixed.txt') as json_file:\n",
    "    \n",
    "    data = json.load(json_file)\n",
    "    \n",
    "    df_flacco = pd.DataFrame.from_records(data)\n",
    "\n",
    "    # features from flacco\n",
    "\n",
    "    flacco_features = df_flacco['flacco features'].apply(pd.Series)\n",
    "    df_flacco = pd.concat([df_flacco.drop('flacco features', axis=1), flacco_features], axis=1)\n",
    "    df_flacco = df_flacco.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.merge(df_onell, df_flacco, on=['n', 'dummy', 'epi', 'neu', 'rug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data before trainig process\n",
    "\n",
    "df_new = df_new.astype(float)\n",
    "df_new = df_new.fillna(0)\n",
    "#df_new = (df_new - df_new.mean()) / df_new.std()\n",
    "#df_new = df_new.fillna(0)\n",
    "\n",
    "X = df_new.drop(['n', 'dummy', 'epi', 'neu', 'rug', 'lambdaOne', 'lambda2', 'crossover', 'mutation', 'runtime', 'runtime over n', 'runtime_mean'], axis=1)\n",
    "X = (X - X.mean()) / X.std()\n",
    "X = X.fillna(0)\n",
    "\n",
    "y = df_new[['lambdaOne', 'lambda2', 'crossover', 'mutation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_sum = 0\n",
    "\n",
    "    inputs = X_train\n",
    "    targets = y_train\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, targets)\n",
    "    loss_sum += loss\n",
    "    grads = model.backward(loss_function)\n",
    "    params = model.parameters()\n",
    "    optimizer.step(grads, params)\n",
    "    acc = eval_accuracy(model, X_val, y_val)\n",
    "    losses.append(loss_sum)\n",
    "    accuracies.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read flacco test data\n",
    "\n",
    "# To fix the probem with the way output data is structured after multiple runs of onell\n",
    "\n",
    "with open('flacco_data/test-data.txt') as raw_file:\n",
    "    with open('flacco_data/test-data_fixed.txt', 'wt') as json_file:\n",
    "        for line in raw_file:\n",
    "            json_file.write(line.replace('}[', '}\\n,'))\n",
    "\n",
    "# Read json data and convert to pandas dataframe\n",
    "\n",
    "df_flacco_test = None\n",
    "\n",
    "with open('flacco_data/test-data_fixed.txt') as json_file:\n",
    "    \n",
    "    data_test = json.load(json_file)\n",
    "    \n",
    "    df_flacco_test = pd.DataFrame.from_records(data_test)\n",
    "\n",
    "    # features from flacco\n",
    "\n",
    "    flacco_features_test = df_flacco_test['flacco features'].apply(pd.Series)\n",
    "    df_flacco_test = pd.concat([df_flacco_test.drop('flacco features', axis=1), flacco_features_test], axis=1)\n",
    "    df_flacco_test = df_flacco_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data before trainig process\n",
    "\n",
    "df_flacco_test = df_flacco_test.astype(float)\n",
    "df_flacco_test = df_flacco_test.fillna(0)\n",
    "\n",
    "X_test = df_flacco_test.drop(['n', 'dummy', 'epi', 'neu', 'rug'], axis=1)\n",
    "X_test = (X_test - X_test.mean()) / X_test.std()\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = X_test\n",
    "res = model.forward(val)\n",
    "\n",
    "buf_res = pd.DataFrame({'lambdaOne': res[:, 0], 'lambda2': res[:, 1], 'crossover': res[:, 2], 'mutation': res[:, 3]})\n",
    "full_res = pd.concat([df_flacco_test, buf_res], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_results.txt', 'w') as write_file:\n",
    "    for index, row in full_res.iterrows():\n",
    "        lambdaOne = row['lambdaOne'] if row['lambdaOne'] > 1 and row['lambdaOne'] < 10.0 else random.uniform(2.0, 9.0)\n",
    "        lambda2 = row['lambda2'] if row['lambda2'] > 1 and row['lambda2'] < 10.0 else random.uniform(2.0, 9.0)\n",
    "        crossover = row['crossover'] if row['crossover'] > 0 and row['crossover'] < 0.25 else random.uniform(0.01, 0.09)\n",
    "        mutation = row['mutation'] if row['mutation'] > 1 and row['mutation'] < 10.0 else random.uniform(1.0, 9.0)\n",
    "        write_file.write('{{\"n\": {}, \"dummy\": {}, \"epi\": {}, \"neu\": {}, \"rug\": {}, \"lambdaOne\":{}, \"lambda2\":{}, \"crossover\":{}, \"mutation\":{}}},\\n'.format(\n",
    "            row['n'], row['dummy'], row['epi'], row['neu'], row['rug'], row['lambdaOne'], row['lambda2'], row['crossover'], row['mutation']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
